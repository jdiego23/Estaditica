{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/dataPunto1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clasificación y la entropía como función objetivo de la clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Utilizar la siguiente tabla para crear un árbol de clasificación de la variable Y a mano con 2 niveles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula la entropía inicial de la variable objetivo \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalEjemplos = len(data)\n",
    "y_counts = data['credito'].value_counts()\n",
    "entropia = 0\n",
    "\n",
    "for count in y_counts:\n",
    "    probability = count / totalEjemplos\n",
    "    entropia += -probability * math.log2(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos una funcion para calcular la entropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcularEntropia(data, caracteristica, etiqueta):\n",
    "    valorCrateristicas = data[caracteristica].unique()\n",
    "    entropia = 0\n",
    "    \n",
    "    for valor in valorCrateristicas:\n",
    "        subconjunto = data[data[caracteristica] == valor]\n",
    "        tamañoSubconjunto = len(subconjunto)\n",
    "        subconjunto_y_counts = subconjunto[etiqueta].value_counts()\n",
    "        EntropiaCondicional = 0\n",
    "        \n",
    "        for count in subconjunto_y_counts:\n",
    "            probability = count / tamañoSubconjunto\n",
    "            EntropiaCondicional += -probability * math.log2(probability)\n",
    "        \n",
    "        entropia += (tamañoSubconjunto / totalEjemplos) * EntropiaCondicional\n",
    "    \n",
    "    return entropia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la ganancia de información para cada característica y elijimos la característica con la mayor ganancia como nodo raíz del árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristicas = data.columns[:-1]\n",
    "mejorCaracteristica = None\n",
    "maximaInformacion = -1\n",
    "\n",
    "for caracteristica in caracteristicas:\n",
    "    informacion = entropia - CalcularEntropia(data, caracteristica, 'credito')\n",
    "    \n",
    "    if informacion > maximaInformacion:\n",
    "        maxima_informacion = informacion\n",
    "        mejorCaracteristica = caracteristica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dividimos los datos en dos conjuntos basados en el valor del nodo raíz y repitemos los pasos previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subConjunto1 = data[data[best_feature] == 0]\n",
    "subConjunto2 = data[data[best_feature] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la entropía y la ganancia de información para cada subconjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EntropiaSubconjunto1 = 0\n",
    "EntropiaSubconjunto2 = 0\n",
    "\n",
    "if len(subConjunto1) > 0:\n",
    "    EntropiaSubconjunto1_y_counts = subConjunto1['credito'].value_counts()\n",
    "    for count in EntropiaSubconjunto1_y_counts:\n",
    "        probability = count / len(subConjunto1)\n",
    "        EntropiaSubconjunto1 += -probability * math.log2(probability)\n",
    "\n",
    "if len(subConjunto2) > 0:\n",
    "    EntropiaSubconjunto2_y_counts = subConjunto2['credito'].value_counts()\n",
    "    for count in EntropiaSubconjunto2_y_counts:\n",
    "        probability = count / len(subConjunto2)\n",
    "        EntropiaSubconjunto2 += -probability * math.log2(probability)\n",
    "\n",
    "informacionEntropiaSubconjunto1 = entropia - EntropiaSubconjunto1\n",
    "informacionEntropiaSubconjunto2 = entropia - EntropiaSubconjunto2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodo raíz: estrato\n",
      "subconjunto 1 - Entropía: 0.0\n",
      "subconjunto 1 - Ganancia de información: 1.0\n",
      "subconjunto 2 - Entropía: 0.0\n",
      "subconjunto 2 - Ganancia de información: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nodo raíz:\", best_feature)\n",
    "print(\"subconjunto 1 - Entropía:\", EntropiaSubconjunto1)\n",
    "print(\"subconjunto 1 - Ganancia de información:\", informacionEntropiaSubconjunto1)\n",
    "print(\"subconjunto 2 - Entropía:\", EntropiaSubconjunto2)\n",
    "print(\"subconjunto 2 - Ganancia de información:\", informacionEntropiaSubconjunto2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrene un árbol utilizando sklearn.tree.DecisionTreeClassifier y compare los resultados. ¿Qué puede concluir son iguales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dividimos los datos uno en características (X) y el otro en variable objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('credito', axis=1)\n",
    "y = data['credito']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividemos los datos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificamosel arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se predice en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediccion = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos las prediciones obtenidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_prediccion)\n",
    "print(\"Precisión del modelo:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compare los resultados. ¿Qué puede concluir son iguales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "En resumen, podemos decir que tanto el árbol de clasificación manual como el modelo entrenado con la biblioteca sklearn lograron una clasificación buena en el conjunto de prueba. Con la prediccion de 1.0 podemos concluir que ambos modelos fueron capaces de llegar a un mismo valor de clasificacion. Esto sugiere que ambos modelos fueron capaces de aprender los patrones presentes en los datos y utilizarlos para hacer predicciones precisas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
